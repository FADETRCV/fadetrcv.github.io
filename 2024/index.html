<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- PAGE settings -->
  <link rel="icon" href="https://templates.pingendo.com/assets/Pingendo_favicon.ico">
  <title>WORKSHOP ON FAIR, DATA EFFICIENT AND TRUSTED COMPUTER VISION</title>
  <meta name="description" content="WORKSHOP ON FAIR, DATA EFFICIENT AND TRUSTED COMPUTER VISION.">
  <meta name="keywords" content="FAIR, DATA EFFICIENT AND TRUSTED COMPUTER VISION">
  <!-- CSS dependencies -->
  <link rel="stylesheet" href="aquamarine.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" type="text/css">
  <!-- Script: Make my navbar transparent when the document is scrolled to top -->
  <script src="js/navbar-ontop.js"></script>
  <!-- Script: Animated entrance -->
  <script src="js/animate-in.js"></script>
</head>

<body class="text-center">
  <!-- Navbar -->
  <nav class="navbar navbar-expand-md fixed-top bg-dark navbar-dark">
    <div class="container">
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbar2SupportedContent" aria-controls="navbar2SupportedContent" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button>
      <div class="collapse navbar-collapse justify-content-center" id="navbar2SupportedContent">
        <ul class="navbar-nav" style="">
          <li class="nav-item mx-2">
            <a class="nav-link" href="#"><i class="fa fa-home fa-lg"></i>&nbsp;Home</a>
          </li>
          <li class="nav-item mx-2" style="">
            <a class="nav-link" href="#submission"><i class="fa fa-paper-plane"></i>&nbsp;Submission</a>
          </li>
		  <li class="nav-item mx-2" style="">
            <a class="nav-link" href="assets/conference/programSchedule.pdf"><i class="fa fa-calendar"></i>&nbsp; Schedule</a>
          </li>
          <li class="nav-item mx-2">
            <a class="nav-link" href="#invited"><i class="fa fa-user fa-fw"></i>Speakers</a>
          </li>
          <li class="nav-item mx-2">
            <a class="nav-link" href="#organizers"><i class="fa fa-fw fa-users"></i>Organizers</a>
          </li>
        </ul>
        <a class="btn navbar-btn mx-2 text-white btn-outline-light" href="https://cmt3.research.microsoft.com/TCV2024/" >CMT</a>
      </div>
    </div>
  </nav>
  <div class="d-flex align-items-center section-aquamarine py-5 cover" style="background-image: url(&quot;assets/conference/cover.jpg&quot;); box-shadow: black 0px 0px 4px;">
    <div class="container">
      <div class="row">
        <div class="text-white mt-5 col-lg-12">
          <h1 class="text-left">2024 IEEE CVPR WORKSHOP ON</h1>
          <h3 class="text-left display-4" style="">FAIR, DATA-EFFICIENT, AND TRUSTED COMPUTER VISION</h3>
          <p class="" style="">in conjunction with IEEE <a href="http://cvpr2024.thecvf.com/">CVPR 2024</a><br>June 17, 2024</p>
          <i class="d-block fa fa-angle-down pt-5 fa-3x" style=""></i>
        </div>
      </div>
    </div>
  </div>
<b><b>
	<div class="py-5 section-parallax" style="background-image: url(&quot;assets/conference/schedule.jpg&quot;);" id="schedule">
  <div class="container section-aquamarine">
    <div class="row">
      <div class="col-md-12">
        <h1 class="text-white mt-4">Schedule<br></h1>
        <div class="row">
          <div class="col-md-12">
            <div class="row">
              <div class="col-md-12">
                <h5 class="">PDT Time</h5>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
      <div class="row text-left text-dark">
        <div class="p-4 col-md-6 col-lg-12" style="">
          <div class="card">
            <div class="card-block text-center card-primary p-2">
              <h2>June 17</h2>
            </div>
            <ul class="list-group list-group-flush">
              <li class="list-group-item list-group-item-success" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;8:45-9:00</b></b>&nbsp;<br><b><b>Welcome Remarks</b></b></li>
              <li class="list-group-item list-group-item-warning" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;9:00-9:25&nbsp;<br>Scale Learning in Image Semantics: A 15-Year Review<br>Liangliang Cao</b></b><br></li>
              <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;9:30-9:40&nbsp;<br>DIA: Diffusion based Inverse Network Attack on Collaborative Inference</b></b></li><b>
                <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b>9:40-9:50&nbsp;</b><br><b><b>Fast-NTK: Parameter-Efficient Unlearning for Large-Scale Models</b></b></li><b>
                <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b>9:50-10:00&nbsp;</b><br><b><b>AR-CP: Uncertainty-Aware Perception in Adverse Conditions with Conformal Prediction and Augmented Reality for Assisted Driving</b></b></li><b></b>
                <li class="list-group-item list-group-item-success"><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;10:00-10:20&nbsp;<br><b>Coffee Break</b></li>
                  <li class="list-group-item list-group-item-warning" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;10:20-10:45&nbsp;<br><b>Rubber Hits the Road: Lessons Learned from DeepFake Detection in real-world<br>Siwei Lyu</b></b><br></li>
                    <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;10:45-10:55&nbsp;<br><b>Mitigating Bias Using Model-Agnostic Data Attribution</b></li>
                    <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;10:55-11:05&nbsp;<br>Practical Region-level Attack against Segment Anything Models</b></li><b>
                      <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;11:05-11:15&nbsp;<br>Towards Explainable Visual Vessel Recognition Using Fine-Grained Classification and Image Retrieval</b></li><b>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;11:15-11:25&nbsp;<br>Enforcing Conditional Independence for Fair Representation Learning and Causal Image Generation</b></li><b>
                      <li class="list-group-item list-group-item-warning"><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;11:25-11:50&nbsp;<br><b>Incentivizing Opt-in and Enabling Opt-out for Text-to-Image Models<br>Richard Zhang</b></b><br></li>
                        <li class="list-group-item list-group-item-success" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;11:50-13:00&nbsp;<br><b>Lunch Break</b></li>
                        <li class="list-group-item list-group-item-warning"><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;13:00-13:25&nbsp;<br><b>Uncovering and Addressing Biases in Diffusion Models<br>R. Ventakesh Babu</b></b><br></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;13:25-13:35&nbsp;<br>Towards Efficient Machine Unlearning with Data Augmentation: Guided Loss-Increasing (GLI) to Prevent the Catastrophic Model Utility Drop</b></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;13:35-13:45&nbsp;<br>ReweightOOD: Loss Reweighting for Distance-based OOD Detection</b></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;13:45-13:55&nbsp;<br>T2FNorm: Train-time Feature Normalization for OOD Detection in Image Classification</b></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;13:55-14:05&nbsp;<br>Our Deep CNN Matchers have Developed Achromatopsia</b></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;14:05-14:15&nbsp;<br>Test-time Assessment of a Models Performance on Unseen Domains via Optimal Transport</b></li>
                        <li class="list-group-item list-group-item-warning"><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;14:15-14:40&nbsp;<br><b>Content Creation Beyond Text to Pixel<br>Yu-Chuan Su</b></b><br></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;14:40-14:50&nbsp;<br>Improving the Robustness of 3D Human Pose Estimation: A Benchmark and Learning from Noisy Input</b></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;14:50-15:00&nbsp;<br>RLNet: Robust Linearized Networks for Efficient Private Inference</b></li>
                        <li class="list-group-item list-group-item-success" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;15:00-15:20&nbsp;<br><b>Coffee Break</b></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;15:20-15:30&nbsp;<br>Robust and Explainable Fine-Grained Visual Classification with Transfer Learning: A Dual-Carriageway Framework</b></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;15:30-15:40&nbsp;<br>Data-free Defense of Black Box Models Against Adversarial Attacks</b></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;15:40-15:50&nbsp;<br>Fractals as Pre-training Datasets for Anomaly Detection and Localization</b></li>
                        <li class="list-group-item list-group-item-info" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i><b><b>&nbsp;15:50-16:00&nbsp;<br>SkipPLUS: Skip the First Few Layers to Better Explain Vision Transformers</b></li>
                        <li class="list-group-item list-group-item-warning"><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;16:00-16:25&nbsp;<br><b>Brain-inspired Design of Vision Transformers<br>Tianming Liu</b></b><br></li>
                                  <b>
                                    <li class="list-group-item list-group-item-success" style=""><i class="mx-auto fa d-inline fa-clock-o text-primary"></i>&nbsp;16:30-17:30&nbsp;<br><b>Closing Remarks and Disperse for Poster Session</b></li><b>
                                      <b>
                                        <b>
                                          <b>
                                            <b>
                                              <b>
                                                <b>
                                                  <b></b>
                                                </b>
                                              </b>
                                            </b>
                                          </b>
                                        </b>
                                      </b>
                                    </b>
                                  </b>
                                </b>
                              </b>
                            </b>
                          </b>
                        </b>
                      </b>
                    </b>
                  </b>
                </b>
              </b>
            </ul><b><b>
              </b></b>
          </div><b><b>
            </b></b>
        </div>
          </b></b>
      </div><b><b>
        </b></b>
    </div><b><b>
      </b></b>
  </div>
      <b><b>
          <div class="py-5 section-parallax" style="background-image: url(&quot;assets/conference/venue.jpg&quot;);">
            <div class="container my-5 bg-light p-4">
              <div class="row mx-auto">
                <div class="col-md-12">
                  <h1 class="mb-3">About the Workshop</h1>
                  <p class="text-justify"><span style="font-weight: normal;">In every walk of life, computer vision and AI systems are playing a significant and increasing role. They are being employed for making mundane day to day decisions such as healthy food choices and dress choices from the wardrobe to match the occasion of the day as well as mission-critical and life-changing decisions such as diagnosis of diseases, detection of financial frauds, and selecting new employees. Many upcoming applications such as autonomous driving to automated cancer treatment recommendations has everyone worrying about the level of trust associated with vision systems today. The concerns are genuine as many weaker sides of modern vision systems have been exposed through adversarial attacks, bias, and lack of explainability in the current rapidly evolving vision systems. While these vision systems are reaping the advantage of the novel learning methods, they exhibit brittleness to minor changes in the input data and lack the capability to explain its decisions to a human. Furthermore, they are unable to address the bias in their training data and are often highly opaque in terms of revealing the lineage of the system and how they were trained and tested. It has been conjectured that the current use of AI is based on only about 20% of the data the world has access to. Rest 80% of the data that can help AI systems is not available because of regulations and compliance requirements around security and privacy. The present AI systems haven’t demonstrated the ability to learn without compromising on the privacy and security of data. Nor can they even assign appropriate credit to the data sources.&nbsp;<br><br>With the ever increasing appetite for data in machine learning, we need to face the reality that for many applications, sufficient data may not be available. Even if raw data is plenty, quality labeled data may be scarce, and if it is not, then relevant labeled data for a particular objective function may not be sufficient. The latter is often the case in tail end of the distribution problems, such as recognizing in autonomous driving that a baby stroller is rolling on the street. The event is rare in training and testing data, but certainly highly critical for the objective function of personal and property damage. Even the performance evaluation of such a situation is challenging. One may stage experiments geared towards particular situations, but this is not a guarantee that the staging conforms to the natural distribution of events, and even if, then there are many tail ends in high dimensional distributions, that are by their nature hard to enumerate manually.&nbsp;<br><br>Many publicly available computer vision datasets are responsible for great progress in visual recognition and analytics. These datasets serve as source of large amounts of training data as well as assessing performance of state-of-the-art competing algorithms. Performance saturation on such datasets has led the community to believe many general visual recognition problems to be close to be solved, with various commercial offerings stemming from models trained on such data. However, such datasets present significant biases in terms of both categories and image quality, thus creating a significant gap between their distribution and the data coming from the real world. For example, many of the publicly available datasets underrepresent certain ethnic and cultural communities and over represent others. Many variations have been observed to impact visual recognition including resolution, illumination and simple cultural variations of similar objects. Systems based on a skewed training dataset are bound to produce skewed results. This mismatch has been evidenced in the significant drop in performance of state of the art models trained on those datasets when applied to images for example of particular gender and/or ethnicity groups for face analytics. It has been shown that such biases may have serious impacts on performance in challenging situations where the outcome is critical either for the subject or to a community. Often research evaluations are quite unaware of those issues, while focusing on saturating the performance on skewed datasets.&nbsp;<br><br>In order to progress toward fair visual recognition truly in the wild, we propose this workshop to understand the underlying issues in bias free and culturally diverse visual recognition.&nbsp;<br><br>Under such circumstances, our workshop on Fair, Data Efficient and Trusted Computer Vision will address four critical issues in enhancing user trust in AI and computer vision systems namely: (i) Fairness, (ii) Data Efficient learning and critical aspects of trust including (ii) explainability, (iii) mitigating adversarial attacks robustly and (iv) improve privacy and security in model building with right level of credit assignment to the data sources along with transparency in lineage.</span></p>
                </div>
              </div>
            </div>
          </div>
          <div class="py-5 section-parallax" style="background-image: url(&quot;assets/conference/venue.jpg&quot;);" id="submission">&gt; <div class="container my-5 bg-light p-4">
              <div class="row mx-auto">
                <div class="col-md-12">
                  <h1 class="mb-3"><b>Submission</b></h1>
                  <h2 class="mb-3 text-left"><br><b>Submission Instructions</b></h2>
                  <p class="lead">
                  </p>
                  <p class="text-justify" style=""><span style="font-weight: normal;"> We solicit submissions of technical papers. The accepted papers will be published in CVPR 2024 workshop proceedings and presented at the workshop. Please submit at the <a href="https://cmt3.research.microsoft.com/TCV2024/">CMT Submission Site</a> &nbsp;<br><br>Submitted technical papers must follow the CVPR paper format and guidelines (<a href="https://cvpr.thecvf.com/Conferences/2024/AuthorGuidelines">see CVPR2024 Author Guidelines</a>). All accepted submissions must be presented by one of the authors.&nbsp;<br><br>Submission deadline: for technical papers is March 25 2024 11:59pm Pacific Time &nbsp;<br>Notification to authors: April 7 2024 11:59pm Pacific Time<br>Camera ready deadline:&nbsp; April 14 2024 11:59pm Pacific Time<br><br>We invite submissions of original work. The review will be double-blind.&nbsp;</span><br></p>
                  <h2 class="display-5 text-left"><br><b>Topics</b></h2>
                </div>
              </div>
              <div class="row">
                <div class="col-md-12">
                  <p class="text-left">&nbsp; &nbsp; We solicit original research papers covering these areas to be submitted to the workshop:<br></p>
                  <ul class="">
                    <li class="text-left">Vision/AI and bias</li>
                    <li class="text-left">Secure machine learning in vision and AI</li>
                    <li class="text-left">Vision/AI model security using blockchain</li>
                    <li class="text-left" style="">Explainability in Vision/AI decisions</li>
                    <li class="text-left">Analytics in encrypted domain</li>
                    <li class="text-left">Secure Vision/AI computing and blockchain</li>
                    <li class="text-left">Vision/AI provenance and lineage</li>
                    <li class="text-left">Trust in Vision/AI</li>
                    <li class="text-left">Privacy in Vision/AI</li>
                    <li class="text-left">Robustness of Vision/AI models</li>
                    <li class="text-left">Vision/AI forensics</li>
                    <li class="text-left">Vision/AI models attribution</li>
                    <li class="text-left">Work that spans across the many dimensions of trust</li>
                    <li class="text-left">Algorithms and theories for learning computer vision models under bias and scarcity</li>
                    <li class="text-left">Methods for exploiting prior knowledge to learn models under bias/scarcity</li>
                    <li class="text-left">Optimization methods designed for learning models from side-channel/alternative/synthetic sources of data</li>
                    <li class="text-left">Domain adaptation methods to bridge train/test data gap</li>
                    <li class="text-left">Methods for studying generalization characteristics of vision models trained from alternative data sources</li>
                    <li class="text-left">Methods of evaluating performance of models under bias/scarcity</li>
                    <li class="text-left">Domain-specific methods designed for important computer vision applications</li>
                    <li class="text-left">Performance characterization of vision algorithms and systems under bias and scarcity</li>
                    <li class="text-left">Continuous re nement of vision models using active/online learning</li>
                    <li class="text-left">Meta-learning models from various existing task-speci c models</li>
                    <li class="text-left">Brave new ideas to learn computer vision models under bias and scarcity</li>
                    <li class="text-left">New algorithms and architectures explicitly designed to reduce bias in visual analytics</li>
                    <li class="text-left">New techniques to balance/manipulate data to reduce bias in visual analytics</li>
                    <li class="text-left">New datasets to improve and measure bias/diversity in visual analytics</li>
                    <li class="text-left">New evaluation protocols to assess and measure bias/diversity in visual analytics</li>
                    <li class="text-left">Generative methods to reduce bias in visual analytics</li>
                    <li class="text-left">Evaluations of bias/diversity of state of the art techniques in visual analytics</li>
                    <li class="text-left">Transfer learning/domain adaptation techniques for more fair visual analytics</li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
          <!-- Cover -->
          <!-- Parallax section -->
          <!-- Parallax section -->
          <!-- Speakers -->

          <!-- Schedule -->
          <div class="py-5 bg-light" id="organizers">
            <div class="container-fluid">
              <div class="row">
                <div class="col-md-12">
                  <h1>Organizers</h1>
                </div>
              </div>
              <div class="row">
                <div class="col-6 col-lg-3">
                  <a href="http://engineering.buffalo.edu/computer-science-engineering/people/faculty-directory.host.html/content/shared/engineering/computer-science-engineering/profiles/faculty/ratha-nalini.html">
                    <img src="assets/conference/Nalini.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                    <h3 class="mb-0"><b>Nalini Ratha</b></h3>
                    <p class="text-muted">University of Buffalo</p>
                  </a>
                </div>
                <div class="col-6 col-lg-3">
                  <a href="https://karanams.github.io/">
                    <img src="assets/conference/Srikrishna.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                    <h3 class="mb-0"><b>Srikrishna Karanam</b></h3>
                    <p class="text-muted">Adobe Research</p>
                  </a>
                </div>
                <div class="col-6 col-lg-3">
                  <a href="http://wuziyan.com/">
                    <img src="assets/conference/Ziyan.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                    <h3 class="mb-0"><b>Ziyan Wu</b></h3>
                    <p class="text-muted">United Imaging Intelligence</p>
                  </a>
                </div>
                <div class="col-6 col-lg-3" style="">
                  <a href="http://iab-rubric.org/">
                    <img src="assets/conference/Mayank.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                    <h3 class="mb-0"><b>Mayank Vatsa</b></h3>
                    <p class="text-muted">IIT Jodhpur</p>
                  </a>
                </div>
				<div class="col-6 col-lg-3">
              <a href="http://iab-rubric.org/">
                <img src="assets/conference/Richa.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                <h3 class="mb-0"><b>Richa Singh</b></h3>
                <p class="text-muted">IIT Jodhpur</p>
              </a>
            </div>
                <div class="col-6 col-lg-3">
                  <a href="https://www.merl.com/people/kpeng">
                    <img src="assets/conference/Kuan-Chuan.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                    <h3 class="mb-0"><b>Kuan-Chuan Peng</b></h3>
                    <p class="text-muted">Mitsubishi Electric Research Laboratories</p>
                  </a>
                </div>
                <div class="col-6 col-lg-3">
                  <a href="https://www.michelemerler.com/">
                    <img src="assets/conference/Michele.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                    <h3 class="mb-0"><b>Michele Merler</b></h3>
                    <p class="text-muted">IBM Research</p>
                  </a>
                </div>
                <div class="col-6 col-lg-3">
                  <a href="http://krvarshney.github.io/">
                    <img src="assets/conference/Kush.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                    <h3 class="mb-0"><b>Kush Varshney</b></h3>
                    <p class="text-muted">IBM Research</p>
                  </a>
                </div>
				<div class="col-6 col-lg-3">
              <a href="https://www.albany.edu/~yy298919/">
                <img src="assets/conference/yiming.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                <h3 class="mb-0"><b>Yiming Ying</b></h3>
                <p class="text-muted">University at Albany</p>
              </a>
            </div>
                <div class="col-6 col-lg-3">
                  <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-sharat">
                    <img src="assets/conference/Sharath.jpg" class="center-block my-3 rounded-circle img-fluid" width="300">
                    <h3 class="mb-0"><b>Sharath Pankanti</b></h3>
                    <p class="text-muted">Microsoft</p>
                  </a>
                </div>
              </div>
            </div>
          </div>
          <!-- Sponsor logos -->
          <!-- Call to action -->
          <div class="py-5 section-aquamarine" id="register" style="">
            <div class="container">
              <div class="row"></div>
            </div>
          </div>
          <!-- Footer -->
          <footer class="text-md-left text-center p-4 bg-dark text-light">
            <div class="container">
              <div class="row">
                <div class="col-md-12 text-center">
                  <p class="text-muted">© Copyright 2024 WORKSHOP ON FAIR, DATA EFFICIENT AND TRUSTED COMPUTER VISION </p>
                </div>
              </div>
            </div>
          </footer>
          <!-- JavaScript dependencies -->
          <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
          <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
          <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
          <!-- Script: Smooth scrolling between anchors in the same page -->
          <script src="js/smooth-scroll.js"></script>
        </b></b>
    </b></b>
</body>

</html>
